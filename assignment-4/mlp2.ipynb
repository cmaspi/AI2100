{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmaspi/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import typing as ty\n",
    "import torchvision\n",
    "\n",
    "# dark background\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "# activation functions\n",
    "def sigmoid(x : ty.Union[float, np.ndarray]) -> ty.Union[float, np.ndarray]:\n",
    "    \"\"\"sigmoid function\n",
    "    \n",
    "    returns 1/(1+exp(-x))\"\"\"\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def relu(x : ty.Union[float, np.ndarray]) -> ty.Union[float, np.ndarray]:\n",
    "    \"\"\"ReLU function\n",
    "    \n",
    "    returns max(0,x)\"\"\"\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "def softmax(x : np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Softmax function\n",
    "    \n",
    "    return [e^x_i/sum(e^x_i) for all i]\"\"\"\n",
    "    denom = np.sum(np.exp(x))\n",
    "    return np.exp(x)/denom\n",
    "\n",
    "def sigmoid_der(x : ty.Union[float, np.ndarray]) -> ty.Union[float, np.ndarray]:\n",
    "    \"\"\"derivative sigmoid function\"\"\"\n",
    "    return sigmoid(x)*(1-sigmoid(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = torchvision.datasets.MNIST(\"files/\")\n",
    "test_ = torchvision.datasets.MNIST(\"files/\", train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = { i:[] for i in range(10) }\n",
    "test_dict = { i:[] for i in range(10) }\n",
    "\n",
    "for image, label in train_:\n",
    "    train_dict[label].append(np.array(image))\n",
    "\n",
    "for image, label in test_:\n",
    "    test_dict[label].append(np.array(image))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, label = [], []\n",
    "for x, y in train_:\n",
    "    train.append(np.array(x)/255)\n",
    "    label.append(y)\n",
    "train = np.array(train)\n",
    "labels = np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train[111], cmap = 'gray')\n",
    "plt.title(f'The image is of the number {label[111]}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor1 = np.sqrt(784/2)\n",
    "factor2 = np.sqrt(49/2)\n",
    "weights = np.array([ np.random.randn(49,784)/factor1, np.random.randn(10, 49)/factor2], dtype = object)\n",
    "biases = np.array([ np.zeros((49,1)), np.zeros((10,1))], dtype = object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x: np.ndarray, weights, biases):\n",
    "    \"\"\"\n",
    "    This function predicts the label of given image\n",
    "    \"\"\"\n",
    "    input = x.reshape(784,1)\n",
    "    activations = [relu, softmax]\n",
    "    for weight, bias, activation  in zip(weights, biases, activations):\n",
    "        input = weight @ input + bias\n",
    "        input = activation(input)\n",
    "    return input.argmax()\n",
    "\n",
    "def accuracy(x,y, weights, biases):\n",
    "    \"\"\"\n",
    "    This function returns accuracy\n",
    "    \"\"\"\n",
    "    predicted = np.ones(y.shape[0])\n",
    "    for i in range(len(x)):\n",
    "        temp = predict(x[i], weights, biases)\n",
    "        if temp != y[i]:\n",
    "            predicted[i] = 0\n",
    "    return np.mean(predicted)        \n",
    "        \n",
    "def shuffle(x,y):\n",
    "    \"\"\"\n",
    "    shuffles the input\"\"\"\n",
    "    l = len(x)\n",
    "    permutation = np.random.permutation(l)\n",
    "    x = x[permutation]\n",
    "    y = y[permutation]\n",
    "    return x,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardpass(input : np.ndarray, weights: np.ndarray, biases : np.ndarray) -> list:\n",
    "    \"\"\"\n",
    "    This function accepts as input, n x 1 dimensional vector, and an array of weight matrix, bias matrix\n",
    "    further, it finds the hidden and final output and returns a list of intial, hidden, final layer\n",
    "    \"\"\"\n",
    "    activations = [relu, softmax]\n",
    "    x_layers = [input]\n",
    "    for weight, bias, activation  in zip(weights, biases, activations):\n",
    "        input = weight @ input + bias\n",
    "        input = activation(input)\n",
    "        x_layers.append(input)\n",
    "    return x_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(_input_ : np.ndarray, weights : np.ndarray, biases :np.ndarray, _label_: np.ndarray):\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    -------\n",
    "    gradients wrt each matrix, and bias. \n",
    "    (np.ndarray for all weight matrix), (np.ndarray for all bias vectors)\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    one image, weight matrix, biases, label for this image\n",
    "\n",
    "    What is being done\n",
    "    ------------------\n",
    "    input is an array of images of size (28 x 28), first each image is flattended\n",
    "    \n",
    "    next, each of the labels is converted to a one-hot vector\n",
    "    \"\"\"\n",
    "    # flattening the image to 784 x 1\n",
    "    input = _input_.reshape(784,1)\n",
    "    label = np.zeros((10,1))\n",
    "    label[_label_] = 1\n",
    "\n",
    "    # output at each layer\n",
    "    x_layers = forwardpass(input, weights, biases)\n",
    "    \n",
    "    delta1 = x_layers[2] - label\n",
    "    dw1 = delta1 @ x_layers[1].T\n",
    "    db1 = delta1\n",
    "    \n",
    "    temp = np.ones_like(x_layers[1])\n",
    "    temp[x_layers[1]<0]=0\n",
    "    delta0 = (weights[1].T @ delta1) * temp\n",
    "    \n",
    "    dw0 = delta0 @ x_layers[0].T\n",
    "    db0 = delta0\n",
    "\n",
    "    dw = np.array([dw0, dw1], dtype = object)\n",
    "    db = np.array([db0, db1], dtype = object)\n",
    "\n",
    "    return dw, db\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = backprop(train[0], weights, biases, labels[0])\n",
    "# i\n",
    "# i = forwardpass(train[0].reshape(784,1), weights, biases)\n",
    "# i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit( input : np.ndarray, labels : np.ndarray, weights : np.ndarray, biases : np.ndarray, batch_size : int = 50, epochs: int = 10, lr: int = 5):\n",
    "    \n",
    "    size = input.shape[0] # number of example in training set\n",
    "    validation = input[int(size*0.8):]\n",
    "    validation_labels = labels[int(size*0.8):]\n",
    "\n",
    "    train = input[:int(size*0.8)]\n",
    "    labels = labels[:int(size*0.8)]\n",
    "    \n",
    "    batches = np.arange(0, train.shape[0], batch_size)\n",
    "\n",
    "    # print(f'Training accuracy : {accuracy(train, labels, weights, biases)}')\n",
    "    # print(f'Validation accuracy : {accuracy(validation, validation_labels, weights, biases)}')\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f'Epoch #{epoch +1 }:')\n",
    "\n",
    "        train, labels = shuffle(train, labels)\n",
    "\n",
    "        for idx in batches:\n",
    "            x = train[idx: idx+batch_size]\n",
    "            y = label[idx: idx+batch_size]\n",
    "\n",
    "            dw, db = None, None\n",
    "            for xx, yy in zip(x,y):\n",
    "                if dw is not None:\n",
    "                    temp1, temp2 = backprop(xx, weights, biases, yy)\n",
    "                    dw += temp1\n",
    "                    db += temp2\n",
    "                else:\n",
    "                    dw,db = backprop(xx, weights, biases, yy)\n",
    "            dw /= batch_size\n",
    "            db /= batch_size\n",
    "            dw = dw * lr\n",
    "            db = db * lr\n",
    "            \n",
    "            # updating the weights, biases\n",
    "            weights -= dw\n",
    "            biases -= db\n",
    "        print(f'Training accuracy : {accuracy(train, labels, weights, biases)}')\n",
    "        print(f'Validation accuracy : {accuracy(validation, validation_labels, weights, biases)}\\n')\n",
    "    return weights, biases\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_216913/3672902195.py:27: RuntimeWarning: overflow encountered in exp\n",
      "  denom = np.sum(np.exp(x))\n",
      "/tmp/ipykernel_216913/3672902195.py:28: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(x)/denom\n",
      "/tmp/ipykernel_216913/3672902195.py:28: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.exp(x)/denom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy : 0.09475\n",
      "Validation accuracy : 0.1\n",
      "\n",
      "Epoch #2:\n",
      "Training accuracy : 0.09475\n",
      "Validation accuracy : 0.1\n",
      "\n",
      "Epoch #3:\n",
      "Training accuracy : 0.09475\n",
      "Validation accuracy : 0.1\n",
      "\n",
      "Epoch #4:\n",
      "Training accuracy : 0.09475\n",
      "Validation accuracy : 0.1\n",
      "\n",
      "Epoch #5:\n",
      "Training accuracy : 0.09475\n",
      "Validation accuracy : 0.1\n",
      "\n",
      "Epoch #6:\n",
      "Training accuracy : 0.09475\n",
      "Validation accuracy : 0.1\n",
      "\n",
      "Epoch #7:\n",
      "Training accuracy : 0.09475\n",
      "Validation accuracy : 0.1\n",
      "\n",
      "Epoch #8:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_216913/323538019.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbiases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbiases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_216913/1021820162.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(input, labels, weights, biases, batch_size, epochs, lr)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdw\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                     \u001b[0mtemp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbiases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                     \u001b[0mdw\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtemp1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0mdb\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtemp2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_216913/2444619130.py\u001b[0m in \u001b[0;36mbackprop\u001b[0;34m(_input_, weights, biases, _label_)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# output at each layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mx_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforwardpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbiases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mdelta1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_216913/3227155118.py\u001b[0m in \u001b[0;36mforwardpass\u001b[0;34m(input, weights, biases)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mx_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m  \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbiases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mx_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "weights, biases = fit(train[:5000], labels[:5000], weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5\n",
      "0 0\n",
      "0 4\n",
      "0 1\n",
      "0 9\n",
      "0 2\n",
      "0 1\n",
      "0 3\n",
      "0 1\n",
      "0 4\n"
     ]
    }
   ],
   "source": [
    "for i,j in zip(train[:10], labels[:10]):\n",
    "    print(predict(i, weights, biases), j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
